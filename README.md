LLMs require instructions to provide response. At the moment, an input and an output.

Intuitively, by learning to write good instructions, we can learn to derive useful outputs.

## Empirical integration  
As the AI hyperbole dissipates, it would be helpful to understand language patterns which can make AI meaningful and relevant in the business of becoming eminently qualified humans. This module delves into foundational, concrete examples which from structured inputs, achieve useful outputs.

We can consider an LLM an inference machine with emergent abilities beyond expectations and training.

We can think of LLMs as patttern matching machines.

Here is a pattern which we can provide.

## Credits

This project was inspired by and incorporates code from the following repositories:

- [nasa-petal bidara](https://github.com/nasa-petal/bidara.git) [^1]  



## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.

___
[^1]:  BIDARA  
    A design and research assistant. What makes this interesting is the [System Prompt](https://github.com/nasa-petal/bidara) 

The web version is under active development and currently has more features than the Discord version.
[^2]:  :rocket: [Try the web version](https://nasa-petal.github.io/bidara-deep-chat/) &nbsp; :octocat: [See the repo](https://github.com/nasa-petal/bidara-deep-chat/)
